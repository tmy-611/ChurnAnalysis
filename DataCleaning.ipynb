{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel: Python 3.10.5\n",
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import TimestampType\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning + Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if not already set in system env vars\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Java\\\\jdk-1.8\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\\\spark-3.5.1-bin-hadoop3\"\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataCleaning\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"OnlineRetail.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Profiling, Anomaly Detection and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Check the number of colummns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  8\n",
      "Number of rows:  541909\n"
     ]
    }
   ],
   "source": [
    "# Check the number of columns and rows\n",
    "print(\"Number of columns: \", len(df.columns))\n",
    "print(\"Number of rows: \", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Abnormal 1: Check and correct Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert datatype of InvoiceDate to timestamp\n",
    "df_cleaned = df.withColumn(\"InvoiceDate\", to_timestamp(\"InvoiceDate\", \"M/d/yyyy H:mm\"))\n",
    "\n",
    "# Re-check schema\n",
    "df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Abnormal 2: Check and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|       1454|       0|          0|        0|    135080|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in original data\n",
    "missing_values = df_cleaned.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in df_cleaned.columns\n",
    "])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Description: 1,454 --> remove since it is hard to guess the product description\n",
    "- CustomerID: 135,080 --> might keep them, change `null` value into `Unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the null values in Description\n",
    "df_cleaned = df_cleaned.filter(df_cleaned.Description.isNotNull())\n",
    "\n",
    "# Change the value in CustomerID into \"Unknown\" for null values\n",
    "df_cleaned = df_cleaned.withColumn(\"CustomerID\", when(df_cleaned.CustomerID.isNull(), \"Unknown\").otherwise(df_cleaned.CustomerID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|          0|       0|          0|        0|         0|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-check for missing values in the cleaned data\n",
    "missing_values = df_cleaned.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in df_cleaned.columns\n",
    "])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Abnormal 3: Check and handle duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  5268\n"
     ]
    }
   ],
   "source": [
    "# Check the number of duplicate rows\n",
    "duplicate_count = df_cleaned.count() - df_cleaned.dropDuplicates().count()\n",
    "print(\"Number of duplicate rows: \", duplicate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df_cleaned = df_cleaned.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  0\n"
     ]
    }
   ],
   "source": [
    "# Re-check the number of duplicate rows\n",
    "duplicate_count = df_cleaned.count() - df_cleaned.dropDuplicates().count()\n",
    "print(\"Number of duplicate rows: \", duplicate_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 Abnormal 4: Handle negative Quantity and UnitPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the number of cancelled order:** The InvoiceNo starts with C (has negative Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of canceled orders:  9251\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|  C536825|    22617|BAKING SET SPACEB...|      -1|2010-12-02 17:27:00|     4.95|     15384|United Kingdom|\n",
      "|  C537251|    22747|POPPY'S PLAYHOUSE...|      -6|2010-12-06 10:45:00|      2.1|   Unknown|United Kingdom|\n",
      "|  C537805|    22197|SMALL POPCORN HOLDER|      -1|2010-12-08 13:18:00|     0.72|     15311|United Kingdom|\n",
      "|  C538103|    22941|CHRISTMAS LIGHTS ...|      -2|2010-12-09 15:13:00|      8.5|     17442|United Kingdom|\n",
      "|  C538768|    84378|SET OF 3 HEART CO...|     -24|2010-12-14 11:34:00|     1.25|     14829|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cancel = df_cleaned.filter(col(\"InvoiceNo\").startswith(\"C\"))\n",
    "print(\"Number of canceled orders: \", cancel.count())\n",
    "cancel.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for invalid values in Quantity and UnitPrice:**\n",
    "- Quantity < 0\n",
    "- UnitPrice < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative Quantity:  9725\n",
      "+---------+--------+\n",
      "|InvoiceNo|Quantity|\n",
      "+---------+--------+\n",
      "|  C536825|      -1|\n",
      "|  C537251|      -6|\n",
      "|  C537805|      -1|\n",
      "|  C538103|      -2|\n",
      "|  C538768|     -24|\n",
      "+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantity has negative value\n",
    "negative_Quantity = df_cleaned.filter(col(\"Quantity\") < 0).count()\n",
    "print(\"Number of negative Quantity: \", negative_Quantity)\n",
    "df_cleaned.filter(col(\"Quantity\") < 0).select(\"InvoiceNo\", \"Quantity\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative UnitPrice:  2\n",
      "+---------+---------+\n",
      "|InvoiceNo|UnitPrice|\n",
      "+---------+---------+\n",
      "|  A563186|-11062.06|\n",
      "|  A563187|-11062.06|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UnitPrice has negative value\n",
    "negative_UnitPrice = df_cleaned.filter(col(\"UnitPrice\") < 0).count()\n",
    "print(\"Number of negative UnitPrice: \", negative_UnitPrice)\n",
    "df_cleaned.filter(col(\"UnitPrice\") < 0).select(\"InvoiceNo\", \"UnitPrice\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that cancelled orders also have the negative Quantity.\n",
    "- The dataset contains 9,251 cancelled orders, while 9,725 orders have a negative quantity.\n",
    "- Therefore, in the Data Cleaning section, when we remove orders with negative quantities, we also remove the cancelled orders at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove abnormal Quantity and UnitPrice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Quantity count: 0\n",
      "Negative UnitPrice count: 0\n",
      "Number of cancelled orders:  0\n"
     ]
    }
   ],
   "source": [
    "# Filter out negative Quantity and UnitPrice\n",
    "df_cleaned = df_cleaned.filter((col(\"Quantity\") > 0) & (col(\"UnitPrice\") > 0))\n",
    "\n",
    "# Check negative Quantity and UnitPrice again\n",
    "print(\"Negative Quantity count:\", df_cleaned.filter(col(\"Quantity\") < 0).count())\n",
    "print(\"Negative UnitPrice count:\", df_cleaned.filter(col(\"UnitPrice\") < 0).count())\n",
    "\n",
    "# Check number of cancelled orders again\n",
    "cancel = df_cleaned.filter(col(\"InvoiceNo\").startswith(\"C\"))\n",
    "print(\"Number of cancelled orders: \", cancel.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6 Abnormal 5: Identify abnormal `StockCode`-`Description` pairs that are not actual products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check abnormal StockCode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------------+\n",
      "|StockCode   |Description                       |\n",
      "+------------+----------------------------------+\n",
      "|POST        |POSTAGE                           |\n",
      "|DOT         |DOTCOM POSTAGE                    |\n",
      "|gift_0001_40|Dotcomgiftshop Gift Voucher �40.00|\n",
      "|C2          |CARRIAGE                          |\n",
      "|gift_0001_30|Dotcomgiftshop Gift Voucher �30.00|\n",
      "|BANK CHARGES|Bank Charges                      |\n",
      "|M           |Manual                            |\n",
      "|AMAZONFEE   |AMAZON FEE                        |\n",
      "|gift_0001_50|Dotcomgiftshop Gift Voucher �50.00|\n",
      "|gift_0001_20|Dotcomgiftshop Gift Voucher �20.00|\n",
      "|gift_0001_10|Dotcomgiftshop Gift Voucher �10.00|\n",
      "|S           |SAMPLES                           |\n",
      "|B           |Adjust bad debt                   |\n",
      "+------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "excluded_stockcodes = [\"POST\", \"DOT\", \"M\", \"C2\", \"BANK CHARGES\",\"S\", \"B\", \"AMAZONFEE\",\n",
    "                       \"gift_0001_10\", \"gift_0001_20\",\"gift_0001_30\",\"gift_0001_40\",\"gift_0001_50\"]\n",
    "\n",
    "# Identify rows with exclued StockCode\n",
    "df_excluded = df_cleaned.filter(col(\"StockCode\").isin(excluded_stockcodes))\n",
    "\n",
    "# Show distinct excluded StockCode - Description pairs\n",
    "df_excluded.select(\"StockCode\", \"Description\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle abnormal StockCode and Description pairs that are not actual products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.filter(~col(\"StockCode\").isin(excluded_stockcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|StockCode|Description|\n",
      "+---------+-----------+\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-check the abnormal stock code\n",
    "df_excluded = df_cleaned.filter(col(\"StockCode\").isin(excluded_stockcodes))\n",
    "df_excluded.select(\"StockCode\", \"Description\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Data cleaning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before cleaning: 541909\n"
     ]
    }
   ],
   "source": [
    "# The number of rows before cleaning\n",
    "rows_before_cleaning = df.count()\n",
    "print(f\"Number of rows before cleaning: {rows_before_cleaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after cleaning: 522541\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows after cleaning\n",
    "rows_after_cleaning = df_cleaned.count()\n",
    "print(f\"Number of rows after cleaning: {rows_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: date (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "|   536384|    84755|COLOUR GLASS T-LI...|      48| 2010-12-01|     0.65|     18074|United Kingdom|\n",
      "|   536385|    22168|ORGANISER WOOD AN...|       2| 2010-12-01|      8.5|     17420|United Kingdom|\n",
      "|   536399|    22632|HAND WARMER RED P...|       6| 2010-12-01|     1.85|     17850|United Kingdom|\n",
      "|   536401|    22767|TRIPLE PHOTO FRAM...|       2| 2010-12-01|     9.95|     15862|United Kingdom|\n",
      "|   536423|    22632|HAND WARMER RED R...|      12| 2010-12-01|      2.1|     18085|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert InvoiceDate data type to DateType\n",
    "df_fe = df_cleaned.withColumn(\"InvoiceDate\", to_date(col(\"InvoiceDate\"), \"M/d/yyyy H:mm\"))\n",
    "df_fe.printSchema()\n",
    "df_fe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2011, 12, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the max date of the dataset\n",
    "max_date = df_fe.agg(max(\"InvoiceDate\")).collect()[0][0]\n",
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|CustomerID|Recency|\n",
      "+----------+-------+\n",
      "|     16250|    261|\n",
      "|     15574|    177|\n",
      "|     15555|     12|\n",
      "|     15271|      7|\n",
      "|     17757|      1|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate recency\n",
    "recency_df = df_fe.groupBy(\"CustomerID\").agg(\n",
    "    datediff(lit(max_date), max(\"InvoiceDate\")).alias(\"Recency\")\n",
    ")\n",
    "recency_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|Frequency|\n",
      "+----------+---------+\n",
      "|     15574|      152|\n",
      "|     15555|      885|\n",
      "|     15271|      264|\n",
      "|     17686|      286|\n",
      "|     17714|       10|\n",
      "+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate frequency (number of transactions per customer)\n",
    "frequency_df = df_fe.groupBy(\"CustomerID\").agg(\n",
    "    count(\"InvoiceNo\").alias(\"Frequency\")\n",
    ")\n",
    "frequency_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|CustomerID|Monetary|\n",
      "+----------+--------+\n",
      "|     15574|  675.64|\n",
      "|     15555| 4791.87|\n",
      "|     15271| 2493.34|\n",
      "|     17686| 5739.46|\n",
      "|     17714|   153.0|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Monetary (Total money spent by customer)\n",
    "monetary_df = df_fe.withColumn(\"TotalPrice\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n",
    "    .groupBy(\"CustomerID\") \\\n",
    "    .agg(round(sum(\"TotalPrice\"), 3).alias(\"Monetary\"))\n",
    "monetary_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+\n",
      "|CustomerID|Recency|Frequency|Monetary|\n",
      "+----------+-------+---------+--------+\n",
      "|     15574|    177|      152|  675.64|\n",
      "|     15555|     12|      885| 4791.87|\n",
      "|     15271|      7|      264| 2493.34|\n",
      "|     17686|      7|      286| 5739.46|\n",
      "|     17714|    320|       10|   153.0|\n",
      "+----------+-------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join all RFM features\n",
    "dfs = [recency_df, frequency_df, monetary_df]\n",
    "rfm_df = reduce(lambda df1, df2: df1.join(df2, \"CustomerID\"), dfs)\n",
    "rfm_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------------+\n",
      "|     Mean_Recency|    Mean_Frequency|    Mean_Monetary|\n",
      "+-----------------+------------------+-----------------+\n",
      "|92.20530565167243|120.54002306805074|2363.834342099193|\n",
      "+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average of Recency, Frequency, and Monetary\n",
    "rfm_df.select(\n",
    "    mean(\"Recency\").alias(\"Mean_Recency\"),\n",
    "    mean(\"Frequency\").alias(\"Mean_Frequency\"),\n",
    "    mean(\"Monetary\").alias(\"Mean_Monetary\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the mean recency, I chose 95 days as the threshold for labeling churn.\n",
    "However, customers who haven’t returned for over 95 days but have high frequency (i.e., they’re loyal) shouldn’t be classified as churned based on recency alone.\n",
    "Therefore, I also used the mean frequency, setting frequency = 120 as a second threshold to more accurately determine whether a customer is churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|     15574|    177|      152|  675.64|    0|\n",
      "|     15555|     12|      885| 4791.87|    0|\n",
      "|     15271|      7|      264| 2493.34|    0|\n",
      "|     17686|      7|      286| 5739.46|    0|\n",
      "|     17714|    320|       10|   153.0|    1|\n",
      "|     13865|     58|       30|  501.56|    0|\n",
      "|     14157|     19|       46|  424.89|    0|\n",
      "|     13610|     12|      215| 1082.33|    0|\n",
      "|     16250|    261|       24|  389.44|    1|\n",
      "|     13282|     18|       37| 1132.14|    0|\n",
      "|     16320|    172|       56| 1038.46|    1|\n",
      "|     13192|     95|       63|  911.94|    0|\n",
      "|     12394|     63|       25| 1080.48|    0|\n",
      "|     13772|     33|      173| 1122.63|    0|\n",
      "|     17506|     75|       14|   302.2|    0|\n",
      "|     18130|     15|       70| 1059.39|    0|\n",
      "|     16504|     25|       83|  465.88|    0|\n",
      "|     15634|     17|       15|  243.55|    0|\n",
      "|     12847|     22|       84|  843.64|    0|\n",
      "|     14204|      2|       39|  150.61|    0|\n",
      "+----------+-------+---------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define thresholds based on the mean values\n",
    "recency_threshold = 95\n",
    "frequency_threshold = 120\n",
    "\n",
    "# Create a new column 'Churn' based on the thresholds\n",
    "rfm_df = rfm_df.withColumn(\n",
    "    \"Churn\",\n",
    "    when((col(\"Recency\") > recency_threshold) & (col(\"Frequency\") <= frequency_threshold), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame with Churn column\n",
    "rfm_df.select(\"CustomerID\", \"Recency\", \"Frequency\", \"Monetary\", \"Churn\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------------------+--------+-------------------+---------+--------------+-----+\n",
      "|CustomerID|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|       Country|Churn|\n",
      "+----------+---------+---------+--------------------+--------+-------------------+---------+--------------+-----+\n",
      "|     12431|   536389|   35004G|SET OF 3 GOLD FLY...|       4|2010-12-01 10:03:00|     6.35|     Australia|    0|\n",
      "|     12431|   536389|    21791|VINTAGE HEADS AND...|      12|2010-12-01 10:03:00|     1.25|     Australia|    0|\n",
      "|     12433|   536532|    22551|PLASTERS IN TIN S...|      24|2010-12-01 13:24:00|     1.65|        Norway|    0|\n",
      "|     12433|   536532|    21980|PACK OF 12 RED RE...|      48|2010-12-01 13:24:00|     0.29|        Norway|    0|\n",
      "|     12433|   536532|    22544|MINI JIGSAW SPACEBOY|      24|2010-12-01 13:24:00|     0.42|        Norway|    0|\n",
      "|     12433|   536532|    22198|LARGE POPCORN HOL...|      48|2010-12-01 13:24:00|     1.65|        Norway|    0|\n",
      "|     12433|   536532|    22554|PLASTERS IN TIN W...|      24|2010-12-01 13:24:00|     1.65|        Norway|    0|\n",
      "|     12583|   536370|    21883|    STARS GIFT TAPE |      24|2010-12-01 08:45:00|     0.65|        France|    0|\n",
      "|     12583|   536370|    22629| SPACEBOY LUNCH BOX |      24|2010-12-01 08:45:00|     1.95|        France|    0|\n",
      "|     12662|   536527|    20713|      JUMBO BAG OWLS|      10|2010-12-01 13:04:00|     1.95|       Germany|    0|\n",
      "|     12738|   536840|    21977|PACK OF 60 PINK P...|      24|2010-12-02 18:27:00|     0.55|       Germany|    1|\n",
      "|     12838|   536415|    22900| SET 2 TEA TOWELS...|       3|2010-12-01 11:57:00|     2.95|United Kingdom|    0|\n",
      "|     12838|   536415|    22321|BIRD DECORATION R...|      12|2010-12-01 11:57:00|     0.85|United Kingdom|    0|\n",
      "|     12838|   536415|    22750|FELTCRAFT PRINCES...|       2|2010-12-01 11:57:00|     3.75|United Kingdom|    0|\n",
      "|     12838|   536415|    22149|FELTCRAFT 6 FLOWE...|       4|2010-12-01 11:57:00|      2.1|United Kingdom|    0|\n",
      "|     12868|   536523|    21259|VICTORIAN SEWING ...|       2|2010-12-01 12:50:00|     5.95|United Kingdom|    1|\n",
      "|     12868|   536523|    22227|HANGING HEART MIR...|      24|2010-12-01 12:50:00|     0.65|United Kingdom|    1|\n",
      "|     12868|   536523|    22111|SCOTTIE DOG HOT W...|       3|2010-12-01 12:50:00|     4.95|United Kingdom|    1|\n",
      "|     12921|   536561|    22750|FELTCRAFT PRINCES...|       4|2010-12-01 15:06:00|     3.75|United Kingdom|    0|\n",
      "|     12947|   536582|    22634|CHILDS BREAKFAST ...|       2|2010-12-01 16:21:00|     9.95|United Kingdom|    1|\n",
      "+----------+---------+---------+--------------------+--------+-------------------+---------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join churn label into transaction-level cleaned data\n",
    "final_df = df_cleaned.join(rfm_df.select(\"CustomerID\", \"Churn\"), on=\"CustomerID\", how=\"left\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Churn rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------------+\n",
      "|Churn| Count|       Percentage|\n",
      "+-----+------+-----------------+\n",
      "|    1| 35735|6.838697824668303|\n",
      "|    0|486806| 93.1613021753317|\n",
      "+-----+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total churn rate\n",
    "churn_rate = final_df.groupBy(\"Churn\").agg(\n",
    "    F.count(\"*\").alias(\"Count\"),\n",
    "    (F.count(\"*\") / final_df.count() * 100).alias(\"Percentage\")\n",
    ")\n",
    "churn_rate.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the churn rate by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------+-------------------+\n",
      "|             Country|total|churned|         churn_rate|\n",
      "+--------------------+-----+-------+-------------------+\n",
      "|              Brazil|   32|     32|                1.0|\n",
      "|  European Community|   57|     57|                1.0|\n",
      "|           Lithuania|   35|     35|                1.0|\n",
      "|        Saudi Arabia|    9|      9|                1.0|\n",
      "|United Arab Emirates|   67|     67|                1.0|\n",
      "|             Lebanon|   45|     45|                1.0|\n",
      "|             Bahrain|   18|     17| 0.9444444444444444|\n",
      "|              Greece|  142|    107| 0.7535211267605634|\n",
      "|               Malta|  109|     45|0.41284403669724773|\n",
      "|               Japan|  321|     97|0.30218068535825543|\n",
      "|         Unspecified|  442|    110|  0.248868778280543|\n",
      "|             Austria|  384|     87|          0.2265625|\n",
      "|              Poland|  325|     61|0.18769230769230769|\n",
      "|               Italy|  741|    114|0.15384615384615385|\n",
      "|            Portugal| 1455|    220|0.15120274914089346|\n",
      "|              Israel|  292|     43|0.14726027397260275|\n",
      "|         Switzerland| 1927|    277|0.14374675661650232|\n",
      "|     Channel Islands|  743|     93|0.12516823687752354|\n",
      "|                 USA|  179|     22|0.12290502793296089|\n",
      "|              Sweden|  427|     49|0.11475409836065574|\n",
      "+--------------------+-----+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Churn rate by Country\n",
    "churn_by_country = final_df.groupBy(\"Country\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total\"),\n",
    "        F.sum(\"churn\").alias(\"churned\")\n",
    "    ) \\\n",
    "    .withColumn(\"churn_rate\", F.col(\"churned\") / F.col(\"total\")) \\\n",
    "    .orderBy(F.col(\"churn_rate\").desc())\n",
    "churn_by_group.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> We see that Brazil, European Community, Lithuania, Saudi Arabia, United Arab Emirates has the 100% churn rate. Let's dive into each country to see what happened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|InvoiceNo|\n",
      "+----------+---------+\n",
      "|12769     |550201   |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brazil_df = final_df.filter((col(\"Churn\") == 1) & (col(\"Country\") == \"Brazil\"))\n",
    "brazil_df.select(\"CustomerID\",\"InvoiceNo\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|12769     |238    |32       |1143.6  |1    |\n",
      "+----------+-------+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the RFM features of the customers\n",
    "brazil_rfm_df = rfm_df.filter(col(\"CustomerID\")==\"12769\")\n",
    "brazil_rfm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There is only one customer from Brazil. They purchased 32 items and then left 238 days ago. That’s why their RFM features don’t meet the churn threshold, with recency > 90 and frequency < 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### European Community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|InvoiceNo|\n",
      "+----------+---------+\n",
      "|15108     |551013   |\n",
      "|15108     |555542   |\n",
      "|15108     |560783   |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EC_df = final_df.filter(col(\"Country\") == \"European Community\")\n",
    "EC_df.select(\"CustomerID\",\"InvoiceNo\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|15108     |141    |57       |1159.25 |1    |\n",
      "+----------+-------+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the RFM features of the customers\n",
    "EC_rfm_df = rfm_df.filter(col(\"CustomerID\")==\"15108\")\n",
    "EC_rfm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There is only one customer from European Community. They purchased 57 items and then left 141 days ago. That’s why their RFM features don’t meet the churn threshold, with recency > 90 and frequency < 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lithuania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|InvoiceNo|\n",
      "+----------+---------+\n",
      "|15332     |537081   |\n",
      "|15332     |537090   |\n",
      "|15332     |537086   |\n",
      "|15332     |537827   |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lithuania_df = final_df.filter(col(\"Country\") == \"Lithuania\")\n",
    "lithuania_df.select(\"CustomerID\",\"InvoiceNo\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|15332     |366    |35       |1661.06 |1    |\n",
      "+----------+-------+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the RFM features of the customers\n",
    "lithuania_rfm_df = rfm_df.filter(col(\"CustomerID\")==\"15332\")\n",
    "lithuania_rfm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There is only one customer from Lithuania. They purchased 35 items and then left 366 days ago. That’s why their RFM features don’t meet the churn threshold, with recency > 90 and frequency < 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saudi Arabia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|InvoiceNo|\n",
      "+----------+---------+\n",
      "|12565     |544838   |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SA_df = final_df.filter(col(\"Country\") == \"Saudi Arabia\")\n",
    "SA_df.select(\"CustomerID\",\"InvoiceNo\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|12565     |288    |9        |145.92  |1    |\n",
      "+----------+-------+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the RFM features of the customers\n",
    "SA_rfm_df = rfm_df.filter(col(\"CustomerID\")==\"12565\")\n",
    "SA_rfm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There is only one customer from Saudo Arabia. They purchased 9 items and then left 288 days ago. That’s why their RFM features don’t meet the churn threshold, with recency > 90 and frequency < 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### United Arab Emirates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|InvoiceNo|\n",
      "+----------+---------+\n",
      "|17829     |543911   |\n",
      "|12739     |565218   |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UAE_df = final_df.filter(col(\"Country\") == \"United Arab Emirates\")\n",
    "UAE_df.select(\"CustomerID\",\"InvoiceNo\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|12739     |99     |37       |975.54  |1    |\n",
      "|17829     |298    |30       |889.24  |1    |\n",
      "+----------+-------+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the RFM features of the customers\n",
    "SA_rfm_df = rfm_df.filter(col(\"CustomerID\").isin(\"12739\", \"17829\"))\n",
    "SA_rfm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There are two customers from United Arab Emirates:\n",
    "- 12739 purchases 37 items and leaves 99 days ago.\n",
    "- 17829 purchases 298 items and leaves 298 days ago.\n",
    "\n",
    "That’s why their RFM features don’t meet the churn threshold, with recency > 90 and frequency < 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lebanon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|CustomerID|InvoiceNo|\n",
      "+----------+---------+\n",
      "|12764     |542276   |\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lebanon_df = final_df.filter(col(\"Country\") == \"Lebanon\")\n",
    "lebanon_df.select(\"CustomerID\",\"InvoiceNo\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+-----+\n",
      "|CustomerID|Recency|Frequency|Monetary|Churn|\n",
      "+----------+-------+---------+--------+-----+\n",
      "|12764     |316    |45       |1693.88 |1    |\n",
      "+----------+-------+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the RFM features of the customers\n",
    "lebanon_rfm_df = rfm_df.filter(col(\"CustomerID\")==\"12764\")\n",
    "lebanon_rfm_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> There is only one customer from Lebanon. They purchased 45 items and then left 316 days ago. That’s why their RFM features don’t meet the churn threshold, with recency > 90 and frequency < 120."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
